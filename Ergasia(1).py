# -*- coding: utf-8 -*-
"""Ergasia1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14r_nu3fgYeSvueEHzdZADjjX3QwmRYEC
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    ConfusionMatrixDisplay, accuracy_score,
    precision_score, recall_score,
    f1_score, roc_auc_score,confusion_matrix)
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from xgboost import XGBClassifier

#file path
file_path = "/content/drive/MyDrive/Dataset2Use_Assignment1.xlsx"

try:
    df = pd.read_excel(file_path)
    print(df.head())
except FileNotFoundError:
    print(f"Error: The file '{file_path}' was not found. Please ensure the path is correct and the file is accessible.")
except Exception as e:
    print(f"An error occurred: {e}")


#Check
if df.isnull().values.any():
    print("Notification: Missing records (NaNs) detected in the dataset.")
    print(df.isnull().sum())
else:
    print("Notification: No missing records (NaNs) found in the dataset.")

#normalization
indicator_columns = df.columns[0:8]

scaler = MinMaxScaler()
df_scaled = df.copy()
df_scaled[indicator_columns] = scaler.fit_transform(df_scaled[indicator_columns])

print("Data successfully normalized. Displaying the first 5 rows of the scaled data:")
print(df_scaled[indicator_columns].head())

#Statistics
healthy_companies = df[df['ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)'] == 1]
bankrupt_companies = df[df['ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)'] == 2]

healthy_stats = healthy_companies[indicator_columns].agg(['min', 'max', 'mean']).transpose()
bankrupt_stats = bankrupt_companies[indicator_columns].agg(['min', 'max', 'mean']).transpose()

#Figure 2
fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=False)

#For Healthy Companies
healthy_stats.plot(kind='bar', ax=axes[0], colormap='viridis', width=0.8)
axes[0].set_title('Figure 2a: Indicator Statistics for Healthy Companies (Status 1)')
axes[0].set_xlabel('Indicators')
axes[0].set_ylabel('Value')
axes[0].tick_params(axis='x', rotation=45)
plt.setp(axes[0].get_xticklabels(), ha='right')
axes[0].legend(title='Statistic')

#For Bankrupt Companies
bankrupt_stats.plot(kind='bar', ax=axes[1], colormap='magma', width=0.8)
axes[1].set_title('Figure 2b: Indicator Statistics for Bankrupt Companies (Status 2)')
axes[1].set_xlabel('Indicators')
axes[1].set_ylabel('Value')
axes[1].tick_params(axis='x', rotation=45)
plt.setp(axes[1].get_xticklabels(), ha='right')
axes[1].legend(title='Statistic')

plt.tight_layout()
plt.show()

#Statistics to show the diference between max and min on each indicator
print("Statistics for Healthy Companies:")
display(healthy_stats)

print("\nStatistics for Bankrupt Companies:")
display(bankrupt_stats)

#Rename columns
df_renamed = df.rename(columns={'ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)': 'Status', 'ΕΤΟΣ': 'Year'})

company_status_by_year = df_renamed.groupby(['Year', 'Status']).size().unstack(fill_value=0)

#Figure 1
fig, ax = plt.subplots(figsize=(12, 6))
company_status_by_year.plot(kind='bar', stacked=False, ax=ax, width=0.8)

ax.set_title('Figure 1: Number of Healthy (1) and Bankrupt (2) Companies Per Year')
ax.set_xlabel('Year')
ax.set_ylabel('Number of Companies')
ax.legend(['Healthy (1)', 'Bankrupt (2)'], title='Company Status')

plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

target_column_name = 'ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)'

y = df_scaled[target_column_name].map({1: 0, 2: 1}).astype(int)
X = df_scaled.drop(columns=[target_column_name, 'ΕΤΟΣ'])

print("Shape of features (X):", X.shape)
print("Shape of target (y):", y.shape)
print("First 5 rows of X:")
print(X.head())
print("First 5 values of y:")
print(y.head())

columns = ['Classifier Name', 'Training/test set', 'Balanced/unbalanced train set',
           'Number of training samples', 'Number of non-healthy companies in training sample',
           'TP', 'TN', 'FP', 'FN', 'ROC-AUC']
results_df = pd.DataFrame(columns=columns)

#random state=42 to ensure that the results can be replicated exctly
#Models
classifiers = [
    ('LDA', LinearDiscriminantAnalysis()),
    ('Logistic Regression', LogisticRegression(random_state=42, solver='liblinear')),
    ('Decision Tree', DecisionTreeClassifier(random_state=42)),
    ('Random Forest', RandomForestClassifier(random_state=42)),
    ('K-NN', KNeighborsClassifier()),
    ('Naïve Bayes', GaussianNB()),
    ('SVM', SVC(probability=True, random_state=42)),
    ('XGBoost', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')) # Added random_state and eval_metric for consistency
]

#Stratified to ensure that each fold has the same % of healthy and bankrupt companies as the og dataset
skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)


fold_count = 0
for train_index, test_index in skf.split(X, y):
    fold_count += 1
    print(f"\n{'='*50}")
    print(f"Processing Fold {fold_count}/{skf.get_n_splits()}...")

    # Extract training and testing sets for the current fold
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    print("Train distribution (Original):")
    print(y_train.value_counts())
    print("Test distribution (Original):")
    print(y_test.value_counts())

    healthy_count_train = y_train.value_counts().get(0, 0)
    bankrupt_count_train = y_train.value_counts().get(1, 0)

    is_balanced = False
    if bankrupt_count_train > 0 and (healthy_count_train / bankrupt_count_train) > 3:
        #How many healthy companies need to be removed
        target_healthy_count = bankrupt_count_train * 3
        num_to_remove = healthy_count_train - target_healthy_count

        healthy_indices = y_train[y_train == 0].index
        #Ensure num_to_remove is an integer and not negative
        num_to_remove = max(0, int(num_to_remove))
        if num_to_remove > 0:
            np.random.seed(42)

            remove_indices = np.random.choice(healthy_indices, size=num_to_remove, replace=False)
            # Create new balanced training sets
            X_train_balanced = X_train.drop(index=remove_indices)
            y_train_balanced = y_train.drop(index=remove_indices)
            is_balanced = True
            balance_status = 'Balanced'
            print(f"  Train set for Fold {fold_count} was unbalanced (Healthy:{healthy_count_train}, Bankrupt:{bankrupt_count_train}).")
            print(f"  Downsampling healthy companies to achieve a 3:1 ratio. New healthy count: {target_healthy_count}")
            print(f"  Balanced X_train shape: {X_train_balanced.shape}, y_train shape: {y_train_balanced.shape}")
        else:
            X_train_balanced = X_train
            y_train_balanced = y_train
            balance_status = 'Unbalanced (ratio <= 3:1)'
            print(f"  Train set for Fold {fold_count} is already balanced (Healthy:{healthy_count_train}, Bankrupt:{bankrupt_count_train}) or close to 3:1 ratio. No downsampling performed.")
    else:
        X_train_balanced = X_train
        y_train_balanced = y_train
        balance_status = 'Unbalanced (ratio <= 3:1)' if bankrupt_count_train > 0 else 'Unbalanced (no bankrupt)'
        print(f"  Train set for Fold {fold_count} is balanced (Healthy:{healthy_count_train}, Bankrupt:{bankrupt_count_train}) or has no bankrupt companies. No downsampling performed.")

    print(f"\n--- Fold {fold_count} FINAL Distributions (Requirement 7) ---")
    print("Balanced Training set distribution:")
    print(y_train_balanced.value_counts())
    print("Test set distribution (Original):")
    print(y_test.value_counts())

    num_train_samples = len(y_train_balanced)
    num_non_healthy_train = y_train_balanced.value_counts().get(1, 0)

    #Loop
    for clf_name, clf in classifiers:
        print(f"\n--- Training {clf_name} for Fold {fold_count} ---")

        clf.fit(X_train_balanced, y_train_balanced)

        #Helper function to evaluate and store metrics
        def evaluate_and_store(X_data, y_true, data_type, current_results_df):

            y_pred = clf.predict(X_data)

            y_proba = None
            if hasattr(clf, "predict_proba"):
                #Check if there are at least two classes in y_true
                if len(np.unique(y_true)) > 1:
                    y_proba = clf.predict_proba(X_data)[:, 1]
                else:
                    #If only one class is present, ROC AUC cannot be calculated (will be NaN)
                    y_proba = None
            elif hasattr(clf, "decision_function"):
                pass

            #Calc confusion matrix
            #Labels are always [0, 1] for binary classification.
            cm = confusion_matrix(y_true, y_pred, labels=[0, 1])
            tn, fp, fn, tp = cm.ravel()

            accuracy = accuracy_score(y_true, y_pred)
            precision = precision_score(y_true, y_pred, zero_division=0)
            recall = recall_score(y_true, y_pred, zero_division=0)
            f1 = f1_score(y_true, y_pred, zero_division=0)
            roc_auc = roc_auc_score(y_true, y_proba) if y_proba is not None and len(np.unique(y_true)) > 1 else np.nan

            print(f"  {data_type} Metrics:")
            print(f"    Accuracy: {accuracy:.2f}")
            print(f"    Precision: {precision:.2f}")
            print(f"    Recall: {recall:.2f}")
            print(f"    F1-score: {f1:.2f}")
            print(f"    AUC ROC: {roc_auc:.2f}")

            #Display
            fig, ax = plt.subplots(figsize=(6, 5))
            ConfusionMatrixDisplay.from_estimator(clf, X_data, y_true, cmap=plt.cm.Blues, ax=ax)
            ax.set_title(f"Fold {fold_count} {clf_name} {data_type} Confusion Matrix")
            plt.show()

            #Store
            new_row = pd.DataFrame([{
                'Classifier Name': clf_name,
                'Training or test set': data_type,
                'Balanced or unbalanced train set': balance_status,
                'Number of training samples': num_train_samples if data_type == 'Training' else len(y_true),
                'Number of non-healthy companies in training sample': num_non_healthy_train if data_type == 'Training' else y_true.value_counts().get(1, 0),
                'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn,
                'ROC-AUC': roc_auc
            }])
            current_results_df = pd.concat([current_results_df, new_row], ignore_index=True)

            return current_results_df

        # Evaluate on training set
        results_df = evaluate_and_store(X_train_balanced, y_train_balanced, 'Training', results_df)

        # Evaluate on test set
        results_df = evaluate_and_store(X_test, y_test, 'Test', results_df)

print("\nClassification analysis complete for all folds and classifiers.")
print("Displaying the first 5 rows of the results_df:")
print(results_df.head())

#csv
output_filename = 'balancedDataOutcomes.csv'
results_df.to_csv(output_filename, index=False)

print(f"Evaluation results saved to {output_filename}")
print("Displaying the first 5 rows of the saved results:")
print(pd.read_csv(output_filename).head())